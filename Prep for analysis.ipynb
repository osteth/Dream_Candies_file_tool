{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "#Setup\n",
    "import pandas as pd\n",
    "import os, csv, pathlib\n",
    "import datetime\n",
    "import configparser\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "#get path to current project repository.\n",
    "ROOT_P = os.path.abspath(os.curdir)\n",
    "\n",
    "#Get all of the file path from the config file.\n",
    "Customer_P = ROOT_P + config['PATHS']['Customer']\n",
    "Invoice_P = ROOT_P + config['PATHS']['Invoice']\n",
    "Item_P = ROOT_P +config['PATHS']['Item']\n",
    "Output_P = config['PATHS']['Output']\n",
    "\n",
    "#Get all of the file names from the config file.\n",
    "Unique_customer_N = config['FILENAMES']['Unique_customers']\n",
    "Full_N = config['FILENAMES']['Full']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------   Reading Input files from: -------------\n",
      "Customer_P = C:\\Users\\swahle\\Documents\\Github\\Dream_Candies_file_tool/extraction_files/customer.csv\n",
      "Invoice_P = C:\\Users\\swahle\\Documents\\Github\\Dream_Candies_file_tool/extraction_files/invoice.csv\n",
      "Item_P = C:\\Users\\swahle\\Documents\\Github\\Dream_Candies_file_tool/extraction_files/invoice_item.csv\n"
     ]
    }
   ],
   "source": [
    "print('---------   Reading Input files from: -------------')\n",
    "print('Customer_P = ' + str(Customer_P))\n",
    "print('Invoice_P = ' + str(Invoice_P))\n",
    "print('Item_P = ' + str(Item_P))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Loading Input files into dataframes -------------\n"
     ]
    }
   ],
   "source": [
    "print('--------- Loading Input files into dataframes -------------')\n",
    "Customer = pd.read_csv(Customer_P.replace('~$','')).replace('\"', '')\n",
    "Invoice = pd.read_csv(Invoice_P.replace('~$','')).replace('\"', '')\n",
    "Item = pd.read_csv(Item_P.replace('~$','')).replace('\"', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Merging Inputs -------------\n"
     ]
    }
   ],
   "source": [
    "print('--------- Merging Inputs -------------')\n",
    "'''Taking all three customer provided datasets and merging them together to create a single\n",
    "master dataframe that can be used to easily reformat, filter, or process to attain any dataset\n",
    "the customer could possibly want extracted from the data.  This takes a bit longer up front in terms\n",
    "of processor time to build this dataframe but makes things much easer in the long run.'''\n",
    "df = pd.merge(Customer, Invoice)\n",
    "merged = pd.merge(df, Item, on=['INVOICE_CODE'])\n",
    "\n",
    "#dropping the invoice totals column because we have line item prices and dont need to store that data.\n",
    "merged.rename(columns = {'AMOUNT_y':'AMOUNT'}, inplace = True)\n",
    "merged = merged.drop(['AMOUNT_x'], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''-------- This chunk removed because it did not fit customer specifications---------'''\n",
    "#splitting off the customer sample data to its own dataframe to save it off for delivery\n",
    "#Unique_customers = merged.drop_duplicates(subset=['CUSTOMER_CODE'])\n",
    "#Unique_customers = pd.DataFrame(Unique_customers, columns = ['CUSTOMER_CODE'])\n",
    "'''-------- This chunk removed because it did not fit customer specifications---------'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Ensuring output filepath exists to prevent errors\n",
    "#path = pathlib.Path(ROOT_P + Output_P + Unique_customer_N)\n",
    "#path.parent.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Writing to disk.... -------------\n"
     ]
    }
   ],
   "source": [
    "print('--------- Writing to disk.... -------------')\n",
    "#Saving off the customer sample data. \n",
    "#Unique_customers.to_csv(ROOT_P + Output_P + Unique_customer_N, index=False, quotechar='\"',\n",
    "                      quoting=csv.QUOTE_NONNUMERIC)\n",
    "'''-------- /This chunk removed because it did not fit customer specifications---------'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------Action Completed!------------------------\n"
     ]
    }
   ],
   "source": [
    "'''Saving off the full merged dataframe.This will allow us to run this script to build and deliver the test set \n",
    "and then we only have to load and filter the data to generate any deliverable instead of reprocessing anything. '''\n",
    "print('--------- Writing to disk.... -------------')\n",
    "# Create today's date, to append to file\n",
    "todaysdatestring = str(datetime.datetime.today().strftime('%Y-%m-%d'))\n",
    "\n",
    "#Ensuring output filepath exists to prevent errors\n",
    "path = pathlib.Path(ROOT_P + Output_P + Full_N + todaysdatestring + '.csv.gz')\n",
    "path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "merged.to_csv(ROOT_P + Output_P + Full_N + todaysdatestring + '.csv.gz',\n",
    "      header=True,\n",
    "      index=False,\n",
    "      compression='gzip',)\n",
    "print(\"------------------------Action Completed!------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
